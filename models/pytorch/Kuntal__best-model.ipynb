{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import torchmetrics\n",
    "from torch.fft import fft, rfft, ifft\n",
    "# import librosa\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from scipy import signal\n",
    "from numba import jit, prange\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from nnAudio.Spectrogram import CQT1992v2, STFT\n",
    "from numba.experimental import jitclass\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from sklearn.metrics import classification_report\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "#torch.multiprocessing.set_start_method('spawn')# good solution !!!!\n",
    "\n",
    "import wandb\n",
    "# wandb.login()\n",
    "os.environ[\"WANDB_MODE\"] = 'disabled'\n",
    "\n",
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(time_series):\n",
    "        \n",
    "    # Scaling the data in the [-1,1] range so as to transform to polar co-ordinates\n",
    "    # for Gramian angular fields.\n",
    "\n",
    "    min_stamp = np.amin(time_series)\n",
    "    max_stamp = np.amax(time_series)\n",
    "    time_series = (2*time_series - max_stamp - min_stamp)/(max_stamp - min_stamp)\n",
    "\n",
    "    # Checking for any floating point accuracy.\n",
    "    time_series = np.where(time_series >= 1., 1., time_series)\n",
    "    time_series = np.where(time_series <= -1., -1., time_series)\n",
    "\n",
    "    return time_series\n",
    "\n",
    "def whiten(x):\n",
    "    # Assuming x has shape (length, channels)\n",
    "    hann = torch.hann_window(x.shape[0], periodic=True, dtype=torch.float32)\n",
    "    whitened_channels = []\n",
    "    \n",
    "    for ch in range(x.shape[1]):\n",
    "        single_channel_data = torch.tensor(x[:, ch], dtype=torch.float32)\n",
    "        spec = fft(single_channel_data * hann)\n",
    "        mag = torch.sqrt(torch.real(spec * torch.conj(spec)))\n",
    "        whitened_channel = ifft(spec / mag) * torch.sqrt(torch.tensor(len(single_channel_data) / 2, dtype=torch.float32))\n",
    "        whitened_channels.append(whitened_channel.real)\n",
    "        \n",
    "    return torch.stack(whitened_channels, dim=1)\n",
    "\n",
    "\n",
    "def apply_bandpass(x, lf=20, hf=500, order=8, sr=2048):\n",
    "    # Generate the filter coefficients\n",
    "    sos = signal.butter(order, [lf, hf], btype='bandpass', output='sos', fs=sr)\n",
    "    normalization = np.sqrt((hf - lf) / (sr / 2))\n",
    "\n",
    "    # Apply the filter\n",
    "    if len(x.shape) == 1:\n",
    "        # Single channel\n",
    "        x *= signal.tukey(x.shape[0], 0.2)\n",
    "        x = signal.sosfiltfilt(sos, x) / normalization\n",
    "    else:\n",
    "        # Multi-channel\n",
    "        num_channels = x.shape[0]\n",
    "        for ch in range(num_channels):\n",
    "            x[ch, :] *= signal.tukey(x[ch, :].shape[0], 0.2)\n",
    "            x[ch, :] = signal.sosfiltfilt(sos, x[ch, :]) / normalization\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load CSV file into a DataFrame\n",
    "DATA_DIR = \"/data/rgura001/ML4GWsearch/g2net-gravitational-wave-detection\"\n",
    "labels_df = pd.read_csv(DATA_DIR+'/training_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use glob to find all the .npy files in all subfolders\n",
    "file_paths = glob.glob(DATA_DIR+'/train/*/*/*/*.npy')\n",
    "\n",
    "# Sort the files\n",
    "file_paths = sorted(file_paths)\n",
    "# Extract filenames from paths and remove '.npy'\n",
    "file_names = [fp.split('/')[-1].replace('.npy', '') for fp in file_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filepath</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000e74ad</td>\n",
       "      <td>/data/rgura001/ML4GWsearch/g2net-gravitational...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001f4945</td>\n",
       "      <td>/data/rgura001/ML4GWsearch/g2net-gravitational...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000661522</td>\n",
       "      <td>/data/rgura001/ML4GWsearch/g2net-gravitational...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00007a006a</td>\n",
       "      <td>/data/rgura001/ML4GWsearch/g2net-gravitational...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000a38978</td>\n",
       "      <td>/data/rgura001/ML4GWsearch/g2net-gravitational...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           filepath  target\n",
       "0  00000e74ad  /data/rgura001/ML4GWsearch/g2net-gravitational...       1\n",
       "1  00001f4945  /data/rgura001/ML4GWsearch/g2net-gravitational...       0\n",
       "2  0000661522  /data/rgura001/ML4GWsearch/g2net-gravitational...       0\n",
       "3  00007a006a  /data/rgura001/ML4GWsearch/g2net-gravitational...       0\n",
       "4  0000a38978  /data/rgura001/ML4GWsearch/g2net-gravitational...       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_df = pd.DataFrame({'id': file_names, 'filepath': file_paths})\n",
    "merged_df = pd.merge(files_df, labels_df, on='id')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_paths = glob.glob(DATA_DIR+'/test/*/*/*/*.npy')\n",
    "\n",
    "# Sort the files\n",
    "test_file_paths = sorted(test_file_paths)\n",
    "# Extract filenames from paths and remove '.npy'\n",
    "test_file_names = [fp.split('/')[-1].replace('.npy', '') for fp in test_file_paths]\n",
    "test_files_df = pd.DataFrame({'id': test_file_names, 'filepath': test_file_paths})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class G2NetDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.dataframe.iloc[idx]['filepath']\n",
    "        label = self.dataframe.iloc[idx]['target']\n",
    "        \n",
    "        # Load .npy file\n",
    "        data = np.load(filepath)\n",
    "        \n",
    "        data = normalize(data)\n",
    "        #data = whiten(data)\n",
    "        data = apply_bandpass(data)\n",
    "        # Convert to PyTorch tensor\n",
    "        data = torch.tensor(data, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        # print(data.shape, label.shape)\n",
    "        \n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G2NetTestDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filepath = self.dataframe.iloc[idx]['filepath']\n",
    "        \n",
    "        # Load .npy file\n",
    "        data = np.load(filepath)\n",
    "        \n",
    "        data = normalize(data)\n",
    "        #data = whiten(data)\n",
    "        data = apply_bandpass(data)\n",
    "        # Convert to PyTorch tensor\n",
    "        data = torch.tensor(data, dtype=torch.float32)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = G2NetDataset(merged_df)\n",
    "test_dataset = G2NetTestDataset(test_files_df)\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "\n",
    "# Randomly split dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for train and validation datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=16)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Encoder(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, input_shape=(4096, 3)):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # Define your architecture here\n",
    "        self.conv1 = nn.Conv1d(input_shape[1], 128, kernel_size=5, padding=2)\n",
    "        self.instance_norm1 = nn.InstanceNorm1d(128)\n",
    "        self.prelu1 = nn.PReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(128, 256, kernel_size=11, padding=5)\n",
    "        self.instance_norm2 = nn.InstanceNorm1d(256)\n",
    "        self.prelu2 = nn.PReLU()\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(256, 512, kernel_size=21, padding=10)\n",
    "        self.instance_norm3 = nn.InstanceNorm1d(512)\n",
    "        self.prelu3 = nn.PReLU()\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.attention_data = nn.Conv1d(512, 256, kernel_size=1)\n",
    "        self.attention_softmax = nn.Conv1d(512, 256, kernel_size=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * input_shape[0] // 4, 512)\n",
    "        self.instance_norm4 = nn.InstanceNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        \n",
    "        self.train_auc = torchmetrics.AUROC(task=\"binary\")\n",
    "        self.val_auc = torchmetrics.AUROC(task=\"binary\")\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.prelu1(self.instance_norm1(self.conv1(x)))\n",
    "        x1 = self.dropout1(x1)\n",
    "        x1 = F.max_pool1d(x1, kernel_size=2)\n",
    "        \n",
    "        x2 = self.prelu2(self.instance_norm2(self.conv2(x1)))\n",
    "        x2 = self.dropout2(x2)\n",
    "        x2 = F.max_pool1d(x2, kernel_size=2)\n",
    "        \n",
    "        conv3 = self.prelu3(self.instance_norm3(self.conv3(x2)))\n",
    "        conv3 = self.dropout3(conv3)\n",
    "        \n",
    "        attention_data = self.attention_data(conv3)\n",
    "        attention_softmax = F.softmax(self.attention_softmax(conv3), dim=2)\n",
    "        \n",
    "        multiply_layer = attention_data * attention_softmax\n",
    "        dense_layer = F.sigmoid(self.instance_norm4(self.fc1(multiply_layer.view(multiply_layer.size(0), -1))))\n",
    "        \n",
    "        output_layer = self.fc2(dense_layer)\n",
    "        return output_layer\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.float()  # Ensure y is a float\n",
    "        y_hat = self(x)\n",
    "        y_hat = y_hat.view(-1)  # Change shape from [batch_size, 1] to [batch_size]\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        self.train_auc(y_hat.sigmoid(), y.int())\n",
    "        self.log('train_auc', self.train_auc, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.float()  # Ensure y is a float\n",
    "        y_hat = self(x)\n",
    "        y_hat = y_hat.view(-1)  # Change shape from [batch_size, 1] to [batch_size]\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.val_auc(y_hat.sigmoid(), y.int())\n",
    "        self.log('val_auc', self.val_auc, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat = y_hat.view(-1) \n",
    "        y_pred_prob = y_hat.sigmoid() \n",
    "        return y_pred_prob\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    wandb_logger = WandbLogger(project='G2Net', log_model='all')\n",
    "    \n",
    "    # Define ModelCheckpoint callback\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_auc',   # Replace 'val_auc' with the actual name of the metric you want to monitor\n",
    "        dirpath='checkpoints/v2/',\n",
    "        filename='best-checkpoint',\n",
    "        save_top_k=1,\n",
    "        mode='max'\n",
    "    )\n",
    "    model = Encoder(input_shape=(4096, 3))\n",
    "    trainer = pl.Trainer(\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        max_epochs=10,\n",
    "        accelerator=\"gpu\", \n",
    "        devices=1,\n",
    "        accumulate_grad_batches=2,\n",
    "        log_every_n_steps=1,\n",
    "        enable_progress_bar = True,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (conv1): Conv1d(3, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (instance_norm1): InstanceNorm1d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (prelu1): PReLU(num_parameters=1)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (conv2): Conv1d(128, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "  (instance_norm2): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (prelu2): PReLU(num_parameters=1)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (conv3): Conv1d(256, 512, kernel_size=(21,), stride=(1,), padding=(10,))\n",
       "  (instance_norm3): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (prelu3): PReLU(num_parameters=1)\n",
       "  (dropout3): Dropout(p=0.2, inplace=False)\n",
       "  (attention_data): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "  (attention_softmax): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "  (fc1): Linear(in_features=262144, out_features=512, bias=True)\n",
       "  (instance_norm4): InstanceNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (train_auc): BinaryAUROC()\n",
       "  (val_auc): BinaryAUROC()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Encoder(input_shape=(4096, 3))\n",
    "trained_model = model.load_from_checkpoint(checkpoint_path='checkpoints/v2/best-checkpoint.ckpt')\n",
    "trained_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/kpal002/miniconda/envs/gwsearchenv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753ccc644a2d4bfc8324c4e35a6c9f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(devices=1)\n",
    "predictions= trainer.predict(trained_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_predictions = [item for sublist in predictions for item in sublist.cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(DATA_DIR+'/sample_submission.csv')\n",
    "submission_df['target'] = flat_predictions\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels, val_predictions=trainer.predict(trained_model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_flat_predictions = [item for sublist in val_predictions for item in sublist.cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_list = []\n",
    "for data, labels in val_dataset:\n",
    "    true_labels_list.append(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_tensor = torch.tensor(val_flat_predictions)\n",
    "# Convert probabilities to predicted labels\n",
    "predicted_labels = (probs_tensor > 0.5).float()\n",
    "\n",
    "# Compute accuracy\n",
    "true_labels = torch.tensor(true_labels_list)  # Assuming true_labels_list is your list of true labels\n",
    "correct = (predicted_labels == true_labels).float().sum()\n",
    "accuracy = correct / len(true_labels)\n",
    "print(f\"Accuracy: {accuracy.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels_list, predicted_labels)\n",
    "\n",
    "# Normalize by row (i.e., by the number of samples in each true class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_percentage = cm_normalized * 100\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(cm_percentage, interpolation='nearest', cmap=plt.cm.viridis)  # Using viridis colormap\n",
    "plt.title('Normalized Confusion Matrix', fontsize=16)\n",
    "plt.colorbar(label='Percentage %')\n",
    "tick_marks = np.arange(2)  # Assuming binary classification\n",
    "plt.xticks(tick_marks, ['Class 0', 'Class 1'], rotation=45, fontsize=12)\n",
    "plt.yticks(tick_marks, ['Class 0', 'Class 1'], fontsize=12)\n",
    "\n",
    "thresh = cm_percentage.max() / 2.\n",
    "for i, j in itertools.product(range(cm_percentage.shape[0]), range(cm_percentage.shape[1])):\n",
    "    plt.text(j, i, f\"{cm_percentage[i, j]:.2f}%\",\n",
    "             horizontalalignment=\"center\",\n",
    "             fontsize=14,\n",
    "             color=\"white\" if cm_percentage[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label', fontsize=14)\n",
    "plt.xlabel('Predicted label', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(true_labels_list, val_flat_predictions)\n",
    "\n",
    "# Compute AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(true_labels_list, predicted_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
